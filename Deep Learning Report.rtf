{\rtf1\ansi\ansicpg1252\cocoartf2758
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue-Bold;\f1\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab560
\pard\pardeftab560\partightenfactor0

\f0\b\fs40 \cf0 \
\pard\pardeftab560\slleading20\pardirnatural\partightenfactor0

\f1\b0\fs26 \cf0 \
\pard\pardeftab560\sa40\partightenfactor0

\f0\b\fs32 \cf0 Overview of analysis\
\
\pard\pardeftab560\slleading20\partightenfactor0

\f1\b0\fs26 \cf0 Using a css file containing information on more than 34,000 organizations that have received funding from a nonprofit called Alphabet Soup, the data analysis conducted will determine the applicants for funding with the best chance of success. Using machine learning and neural networks, a target and features are identified from 11 columns of data concerning applicants, their application type, income classification, amount requested and whether the money was used successfully.\
\
\pard\pardeftab560\sa40\partightenfactor0

\f0\b\fs32 \cf0 Data Processing\
\
\pard\pardeftab560\slleading20\partightenfactor0

\f1\b0\fs26 \cf0 Variable for the target was the \'93Is successful\'94 column, while other columns, such as name, application type, affiliation, classification and use case were variables.\
\
Dropped variable was EIN, which was not needed for analysis.\
\
\pard\pardeftab560\sa40\partightenfactor0

\f0\b\fs32 \cf0 Compiling, Training and Evaluating the Model\
\
\pard\pardeftab560\slleading20\partightenfactor0

\f1\b0\fs26 \cf0 During the optimization phase, many variations were run, with adjustments to number of neurons, number of hidden layers, activation layers and changes to classification cutoff. Using three hidden nodes improved accuracy without compromising data loss. As the value in hidden nodes climbed, improving accuracy, it also created a higher loss of data, often resulting in a loss of more than 55%. Using three layers, with a moderate number assigned to hidden nodes and better fitting the scale/size of data improved accuracy and resulted in a lower loss of data. Target model performance was achieved at 79.3%}